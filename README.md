# Analysing-Titanic-Survival-Data-using-Spark-ML-pyspark-
Exploratory data analysis (EDA) for titanic Survivor dataset .Titanic
survivor dataset captures the various details of people who survived or not survived in the
shipwreck. Using this data,we will analysing the dataset to summarize their main characteristics.
we will build models which predicts probability of someone’s survival based on attributes like sex,
cabin etc. It’s a classification problem using some machine learning algorithms like Logistic Regression
and Support Vector Machine (SVM).we will use Apache Spark with python.
Apache Spark is one the most widely used framework when it comes to handling and working with
Big Data and Python is one of the most widely used programming languages for Data Analysis, Machine
Learning and much more. So, why not use them together? This is where Spark with Python
also known as PySpark . Spark was developed in Scala language, which is very much similar to
Java. It compiles the program code into bytecode for the JVM for spark big data processing.
To support Spark with python, the Apache Spark community released PySpark.Although like i said
Spark was designed in scala, which makes it almost 10 times faster than Python, but Scala is faster
only when the number of cores being used is less. As most of the analysis and process nowadays
require a large number of cores,and Scala has SparkMLlib it doesn’t have enough libraries and
tools for Machine Learning. For programmers Python is comparatively easier to learn because of
its syntax and standard libraries. Moreover, it’s a dynamically typed language, which means RDDs
can hold objects of multiple types.
4
